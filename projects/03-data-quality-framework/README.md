# ‚úÖ Automated Data Quality Framework ‚Äî Great Expectations + DLT + Azure Monitor

> Framework reutilizable de validaci√≥n de datos en m√∫ltiples capas del pipeline Medallion. Incluye expectations declarativas, alertas autom√°ticas, dashboard de m√©tricas de calidad y tabla de cuarentena.

[![Great Expectations](https://img.shields.io/badge/Great_Expectations-FF6F00?style=flat-square)](#)
[![Databricks](https://img.shields.io/badge/Databricks_DLT-FF3621?style=flat-square&logo=databricks&logoColor=white)](#)
[![Azure Monitor](https://img.shields.io/badge/Azure_Monitor-0078D4?style=flat-square)](#)
[![pytest](https://img.shields.io/badge/pytest-0A9EDC?style=flat-square&logo=pytest&logoColor=white)](#)

---

## üéØ Contexto del Proyecto

### Problema

En un pipeline de datos con **50M registros/d√≠a** y **35 tablas** en el Data Lakehouse, la calidad de datos se verificaba manualmente (spot checks en Excel). Problemas descubiertos en producci√≥n inclu√≠an: registros con IDs nulos que romp√≠an JOINs downstream, fechas fuera de rango que distorsionaban reportes, duplicados que inflaban m√©tricas de negocio, y cambios de schema no comunicados que causaban fallos silenciosos.

### Impacto

- **48 horas promedio** para detectar un problema de calidad
- **2 reportes regulatorios** con errores que generaron observaciones de la SBS
- **3 incidentes** donde dashboards ejecutivos mostraron datos incorrectos

### Objetivo

Construir un framework de calidad de datos que:
- Valide **100% de las tablas Gold** autom√°ticamente
- Detecte problemas en **< 15 minutos** (vs 48 horas)
- Rechace registros inv√°lidos a **cuarentena** sin detener el pipeline
- Proporcione **m√©tricas de calidad** visibles para todo el equipo

---

## üèõÔ∏è Arquitectura

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      PIPELINE DE DATOS                         ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ
‚îÇ  ‚îÇ  BRONZE  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí‚îÇ  SILVER  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí‚îÇ   GOLD   ‚îÇ         ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ
‚îÇ       ‚îÇ                   ‚îÇ                   ‚îÇ                ‚îÇ
‚îÇ       ‚ñº                   ‚ñº                   ‚ñº                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ
‚îÇ  ‚îÇ Schema   ‚îÇ        ‚îÇ   DLT    ‚îÇ        ‚îÇ  Great   ‚îÇ         ‚îÇ
‚îÇ  ‚îÇInference ‚îÇ        ‚îÇExpecta-  ‚îÇ        ‚îÇExpecta-  ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ+ Basic   ‚îÇ        ‚îÇ  tions   ‚îÇ        ‚îÇ  tions   ‚îÇ         ‚îÇ
‚îÇ  ‚îÇValidation‚îÇ        ‚îÇ(declarati‚îÇ        ‚îÇ (Suite   ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ          ‚îÇ        ‚îÇ   ve)    ‚îÇ        ‚îÇ  120+    ‚îÇ         ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ  rules)  ‚îÇ         ‚îÇ
‚îÇ       ‚îÇ                   ‚îÇ              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ
‚îÇ       ‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ                   ‚îÇ               ‚îÇ
‚îÇ       ‚îî‚îÄ‚îÄ‚îÄ‚Üí‚îÇCUARENTENA‚îÇ‚Üê‚îÄ‚îÄ‚îò                   ‚îÇ               ‚îÇ
‚îÇ            ‚îÇ  (Delta) ‚îÇ                       ‚îÇ               ‚îÇ
‚îÇ            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                       ‚îÇ               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
                    ‚îÇ                           ‚îÇ
                    ‚ñº                           ‚ñº
          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
          ‚îÇ   Azure Monitor  ‚îÇ      ‚îÇ   Power BI Dashboard ‚îÇ
          ‚îÇ   + Log Analytics‚îÇ      ‚îÇ   M√©tricas de Calidad‚îÇ
          ‚îÇ                  ‚îÇ      ‚îÇ   + Tendencias       ‚îÇ
          ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ  ‚îÇ   Alertas  ‚îÇ  ‚îÇ
          ‚îÇ  ‚îÇ  Teams +   ‚îÇ  ‚îÇ
          ‚îÇ  ‚îÇ  PagerDuty ‚îÇ  ‚îÇ
          ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üîÄ Capas de Validaci√≥n

### Capa 1: Bronze (Schema & Completitud)

```python
# Auto Loader con schema inference + enforcement
@dlt.table(comment="Transacciones raw con schema validado")
@dlt.expect("archivo_no_vacio", "_rescued_data IS NULL")
@dlt.expect("timestamp_presente", "event_timestamp IS NOT NULL")
def bronze_transacciones():
    return (
        spark.readStream.format("cloudFiles")
        .option("cloudFiles.format", "json")
        .option("cloudFiles.inferColumnTypes", "true")
        .option("cloudFiles.schemaEvolutionMode", "addNewColumns")
        .option("rescuedDataColumn", "_rescued_data")
        .load("abfss://bronze@storage.dfs.core.windows.net/txn/")
    )
```

### Capa 2: Silver (Reglas de Negocio ‚Äî DLT Expectations)

```python
@dlt.table(comment="Transacciones limpias con calidad validada")
@dlt.expect_or_drop("id_no_nulo", "transaccion_id IS NOT NULL")
@dlt.expect_or_drop("monto_positivo", "monto > 0")
@dlt.expect_or_drop("cuenta_valida", "cuenta_id IS NOT NULL AND LENGTH(cuenta_id) >= 8")
@dlt.expect("fecha_rango", "fecha >= '2020-01-01' AND fecha <= current_date()")
@dlt.expect("email_formato", "email IS NULL OR email RLIKE '^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'")
@dlt.expect("sucursal_existe", "sucursal_id IN (SELECT sucursal_id FROM silver.dim_sucursales)")
def silver_transacciones():
    return (
        dlt.read_stream("bronze_transacciones")
        .dropDuplicates(["transaccion_id"])
        .withColumn("fecha", to_date("event_timestamp"))
        .withColumn("monto", col("monto").cast("decimal(18,2)"))
    )
```

### Capa 3: Gold (Reconciliaci√≥n ‚Äî Great Expectations)

```python
# great_expectations/suites/gold_transacciones_suite.py
import great_expectations as gx

context = gx.get_context()

suite = context.add_expectation_suite("gold_transacciones_daily")

# Volumetr√≠a: el count de hoy debe estar dentro del ¬±20% del promedio
suite.add_expectation(
    gx.expectations.ExpectTableRowCountToBeBetween(
        min_value=40_000_000,   # -20% del promedio diario
        max_value=60_000_000    # +20% del promedio diario
    )
)

# Completitud: columnas cr√≠ticas 100% no nulas
for col in ["transaccion_id", "cuenta_id", "monto", "fecha"]:
    suite.add_expectation(
        gx.expectations.ExpectColumnValuesToNotBeNull(column=col)
    )

# Integridad referencial: todas las sucursales existen en dim
suite.add_expectation(
    gx.expectations.ExpectColumnDistinctValuesToBeInSet(
        column="sucursal_id",
        value_set=valid_sucursales  # cargado de dim_sucursales
    )
)

# Consistencia: totales diarios cuadran con fuente
suite.add_expectation(
    gx.expectations.ExpectColumnSumToBeBetween(
        column="monto",
        min_value=source_total * 0.999,  # Tolerancia 0.1%
        max_value=source_total * 1.001
    )
)

# Freshness: datos de hoy presentes
suite.add_expectation(
    gx.expectations.ExpectColumnMaxToBeBetween(
        column="fecha",
        min_value=today,
        max_value=today
    )
)
```

---

## üîî Sistema de Alertas

```python
# monitoring/alert_handler.py
import requests
from azure.monitor.ingestion import LogsIngestionClient

def send_quality_alert(table_name, failed_expectations, severity):
    """Env√≠a alerta a Teams y registra en Log Analytics"""
    
    # 1. Azure Monitor custom metric
    monitor_client = LogsIngestionClient(endpoint, credential)
    monitor_client.upload(
        rule_id=dcr_id,
        stream_name="Custom-DataQuality_CL",
        logs=[{
            "TimeGenerated": datetime.utcnow().isoformat(),
            "TableName": table_name,
            "FailedExpectations": len(failed_expectations),
            "Severity": severity,
            "Details": str(failed_expectations)
        }]
    )
    
    # 2. Teams webhook (critical only)
    if severity == "critical":
        requests.post(TEAMS_WEBHOOK, json={
            "@type": "MessageCard",
            "themeColor": "FF0000",
            "summary": f"üö® Data Quality Alert: {table_name}",
            "sections": [{
                "activityTitle": f"Failed: {len(failed_expectations)} expectations",
                "facts": [{"name": e["name"], "value": e["detail"]} 
                          for e in failed_expectations[:5]]
            }]
        })
```

```kusto
// Log Analytics KQL: dashboard de calidad
DataQuality_CL
| where TimeGenerated > ago(7d)
| summarize 
    TotalChecks = count(),
    FailedChecks = countif(FailedExpectations > 0),
    AvgFailedPct = avg(FailedExpectations * 1.0 / TotalExpectations * 100)
  by bin(TimeGenerated, 1d), TableName
| extend PassRate = round((TotalChecks - FailedChecks) * 100.0 / TotalChecks, 2)
| order by TimeGenerated desc
```

---

## üìÅ Estructura del Repositorio

```
03-data-quality-framework/
‚îú‚îÄ‚îÄ great_expectations/
‚îÇ   ‚îú‚îÄ‚îÄ gx/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ expectations/          # Custom expectations
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ expect_referential_integrity.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ expect_daily_volume_stable.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ checkpoints/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gold_daily_checkpoint.yml
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ silver_hourly_checkpoint.yml
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ suites/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ gold_transacciones.json
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ gold_clientes.json
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ gold_siniestralidad.json
‚îÇ   ‚îî‚îÄ‚îÄ great_expectations.yml     # GX project config
‚îÇ
‚îú‚îÄ‚îÄ dlt_expectations/
‚îÇ   ‚îú‚îÄ‚îÄ bronze_expectations.py     # Schema + completitud
‚îÇ   ‚îú‚îÄ‚îÄ silver_expectations.py     # Reglas de negocio
‚îÇ   ‚îî‚îÄ‚îÄ quarantine_handler.py      # L√≥gica de cuarentena
‚îÇ
‚îú‚îÄ‚îÄ monitoring/
‚îÇ   ‚îú‚îÄ‚îÄ alert_handler.py           # Teams + Log Analytics
‚îÇ   ‚îú‚îÄ‚îÄ kql_queries/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ quality_dashboard.kql
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ trend_analysis.kql
‚îÇ   ‚îú‚îÄ‚îÄ alerts.bicep               # Azure Monitor alert rules
‚îÇ   ‚îî‚îÄ‚îÄ teams_webhook_config.json
‚îÇ
‚îú‚îÄ‚îÄ dashboards/
‚îÇ   ‚îú‚îÄ‚îÄ data_quality_report.pbix   # Power BI dashboard
‚îÇ   ‚îî‚îÄ‚îÄ quality_metrics.sql        # Queries para el dashboard
‚îÇ
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ test_expectations.py       # pytest: validar las expectations
‚îÇ   ‚îú‚îÄ‚îÄ test_quarantine.py         # pytest: l√≥gica de cuarentena
‚îÇ   ‚îî‚îÄ‚îÄ fixtures/
‚îÇ       ‚îú‚îÄ‚îÄ valid_data.json
‚îÇ       ‚îî‚îÄ‚îÄ invalid_data.json
‚îÇ
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ expectation_catalog.md     # Cat√°logo de 120+ reglas
‚îÇ   ‚îú‚îÄ‚îÄ runbook_quality_alert.md   # Qu√© hacer cuando llega una alerta
‚îÇ   ‚îî‚îÄ‚îÄ onboarding.md              # C√≥mo agregar expectations a una tabla nueva
‚îÇ
‚îú‚îÄ‚îÄ azure-pipelines.yml
‚îî‚îÄ‚îÄ README.md
```

---

## üí∞ Costos Estimados

| Componente | Detalle | USD/mes |
|-----------|---------|---------|
| Great Expectations | Open-source (sin licencia) | $0 |
| DLT Expectations | Incluido en Databricks compute | $0 (incluido) |
| Log Analytics | ~5 GB de logs de calidad/mes | $12 |
| Azure Monitor Alerts | 10 alert rules | $5 |
| Power BI (dashboard) | 1 report en workspace existente | $0 (incluido) |
| Compute adicional | GX checkpoint execution (~2 hrs/d√≠a) | $45 |
| **TOTAL** | | **~$62/mes** |

> üí° El framework cuesta ~$62/mes y previene incidentes que costaban **$15,000+/incidente** en horas de investigaci√≥n y correcci√≥n.

---

## üìä M√©tricas de Impacto

| M√©trica | Antes | Despu√©s | Mejora |
|---------|-------|---------|--------|
| Tiempo de detecci√≥n | 48 horas | < 15 minutos | **99.5% m√°s r√°pido** |
| Cobertura de validaci√≥n | ~10% (spot checks) | 100% tablas Gold | **10x cobertura** |
| Incidentes en dashboards | 3/trimestre | 0 en 6 meses | **100% eliminados** |
| Observaciones regulatorias | 2/a√±o | 0 | **100% eliminadas** |
| Registros en cuarentena | No exist√≠a | ~2.3% detectado/d√≠a | **Visibilidad total** |

---

## üîÆ Mejoras Futuras

- [ ] **Anomaly detection con ML** sobre las m√©tricas de calidad (detecci√≥n de drift)
- [ ] **Data contracts** entre equipos productores y consumidores
- [ ] **SLA monitoring** con penalties autom√°ticas cuando la calidad baja del threshold
- [ ] **Purview integration** para vincular clasificaci√≥n PII con expectations
- [ ] **Auto-remediation** para problemas conocidos (ej: auto-OPTIMIZE cuando small files > threshold)

---

## üìÑ Licencia

Proyecto demostrativo. Datos sint√©ticos.
